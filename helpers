#!/bin/bash

# bail out if anything fails
set -e

setup_eks () {
  echo ">>> setup_eks starting..."

  echo ">>> provisioning infra with terraform..."
  cd terraform
  terraform init -input=false
  terraform apply -input=false -auto-approve

  echo ">>> configure kubectl for eks..."
  TF_OUTPUT=$(terraform output -json)
  CLUSTER_NAME="$(echo ${TF_OUTPUT} | jq -r .kubernetes_cluster_name.value)"
  aws eks update-kubeconfig --name ${CLUSTER_NAME}

  echo ">>> checking kubectl..."
  kubectl version
  kubectl get nodes
  kubectl config current-context
  kubectl config view

  echo ">>> setup_eks complete"
}

helm_init () {
  echo ">>> helm_init starting..."
  # initialize helm / tiller
  helm init
  kubectl create serviceaccount --namespace kube-system tiller
  kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
  kubectl patch deploy --namespace kube-system tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}'
  echo ">>> helm_init complete"
}

setup_monitoring () {
  echo ">>> setup_monitoring starting..."

  kubectl create namespace monitoring

  # install prometheus
  helm install stable/prometheus \
      --name prometheus \
      --namespace monitoring \
      --set alertmanager.persistentVolume.storageClass="gp2" \
      --set server.persistentVolume.storageClass="gp2"

  # install grafana
  helm install stable/grafana \
      --name grafana \
      --namespace monitoring \
      --set persistence.storageClassName="gp2" \
      --set adminPassword="notadmin" \
      --set datasources."datasources\.yaml".apiVersion=1 \
      --set datasources."datasources\.yaml".datasources[0].name=Prometheus \
      --set datasources."datasources\.yaml".datasources[0].type=prometheus \
      --set datasources."datasources\.yaml".datasources[0].url=http://prometheus-server.prometheus.svc.cluster.local \
      --set datasources."datasources\.yaml".datasources[0].access=proxy \
      --set datasources."datasources\.yaml".datasources[0].isDefault=true \
      --set service.type=LoadBalancer

  # check prometheus namespace
  kubectl get all -n monitoring

  # debug
  #kubectl port-forward -n prometheus deploy/prometheus-server 8080:9090

  # get grafana elb url
  export ELB=$(kubectl get svc -n grafana grafana -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
  echo "grafana_elb_url: http://$ELB"

  echo ">>> setup_monitoring complete"
}

cleanup_monitoring () {
  echo ">>> cleanup_monitoring starting..."
  # delete prometheus / grafana
  helm del --purge grafana
  helm del --purge prometheus
  kubectl delete namespace monitoring
  echo ">>> cleanup_monitoring complete"
}

cleanup_tiller () {
  echo ">>> cleanup_tiller starting..."
  # delete cluster tiller
  kubectl get all --all-namespaces | grep tiller
  kubectl delete deployment tiller-deploy -n kube-system
  kubectl delete service tiller-deploy -n kube-system
  kubectl get all --all-namespaces | grep tiller
  echo ">>> cleanup_tiller complete"
}

teardown () {
  echo ">>> teardown starting..."

  echo ">>> destroying infra with terraform..."
  cd terraform
  terraform destroy -auto-approve

  echo ">>> cleanup..."
  rm -rf .terraform terraform.tfstate*
  rm -rf ~/.kube/config

  echo ">>> teardown complete"
}

"$@"
